{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mlpipeline\n",
    "Data reformat , preprocess, feature engineering, train, evaluate model and generate submission \n",
    "- <a href='#1'>1. feature_engineering</a> \n",
    "- <a href='#2'>2. train</a> \n",
    "- <a href='#3'>3. predict</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "from time import time\n",
    "from datetime import timedelta, datetime\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from dinglingling import wx_reminder\n",
    "import torch\n",
    "\n",
    "sys.path.append('../')\n",
    "import conf\n",
    "from mlpipeline import (\n",
    "    feature_engineering_pandas,\n",
    "    train,\n",
    "    predict,\n",
    ")\n",
    "from utils import (\n",
    "    check_columns,\n",
    "    check_nan_value,\n",
    "    load_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.width',100)\n",
    "sns.set(rc={'figure.figsize':(20,10)})\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "warnings.simplefilter('ignore', np.RankWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "SCKEY = 'SCU92138T03d57ff9d4b08ced24c2cceb440cd3bd5e843242680de'  # used for reminding when feature engineering or model training completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def __dummy():\n",
    "    pass\n",
    "\n",
    "@wx_reminder(SCKEY=SCKEY, remind_started=True)  \n",
    "def feature_engineering_wrapper(params):\n",
    "        \"\"\"\n",
    "        wrapper for feature engineering func \n",
    "        for reminding when it completes\n",
    "        \"\"\"\n",
    "        train_fe_df, test_fe_df = feature_engineering_pandas(**params)\n",
    "        \n",
    "        return train_fe_df, test_fe_df\n",
    "    \n",
    "@wx_reminder(SCKEY=SCKEY, remind_started=True)  \n",
    "def train_wrapper(params):\n",
    "        if params['is_eval']:\n",
    "            _,_ = train(**params)\n",
    "        else:\n",
    "            if params['model_type'] == 'neural':\n",
    "                model = train(**params) \n",
    "                return model\n",
    "            else:\n",
    "                model, scaler = train(**params) \n",
    "                return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5G\t../data/ad_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.bin\r\n",
      "1.5G\t../data/ad_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy\r\n",
      "249M\t../data/ad_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_test_fe_df.feather\r\n",
      "244M\t../data/ad_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_train_fe_df.feather\r\n",
      "63M\t../data/ad_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl\r\n",
      "29M\t../data/advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.bin\r\n",
      "29M\t../data/advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy\r\n",
      "195M\t../data/advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_test_fe_df.feather\r\n",
      "195M\t../data/advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_train_fe_df.feather\r\n",
      "1008K\t../data/advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl\r\n",
      "437M\t../data/creative_advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_test_fe_df.feather\r\n",
      "412M\t../data/creative_advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_train_fe_df.feather\r\n",
      "1.7G\t../data/creative_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.bin\r\n",
      "1.7G\t../data/creative_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy\r\n",
      "250M\t../data/creative_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_test_fe_df.feather\r\n",
      "245M\t../data/creative_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_train_fe_df.feather\r\n",
      "71M\t../data/creative_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl\r\n",
      "3.9G\t../data/creative_id_window_150_dim_300_sg_1_hs_0_iter_10_embedding.bin\r\n",
      "3.9G\t../data/creative_id_window_150_dim_300_sg_1_hs_0_iter_10_embedding.npy\r\n",
      "250M\t../data/creative_id_window_150_dim_300_sg_1_hs_0_iter_10_neural_test_fe_df.feather\r\n",
      "245M\t../data/creative_id_window_150_dim_300_sg_1_hs_0_iter_10_neural_train_fe_df.feather\r\n",
      "71M\t../data/creative_id_window_150_dim_300_sg_1_hs_0_iter_10_vocab.pkl\r\n",
      "3.9G\t../data/creative_id_window_150_dim_300_sg_1_hs_1_embedding.npy\r\n",
      "3.9G\t../data/creative_id_window_150_dim_300_sg_hs_embedding.bin\r\n",
      "71M\t../data/creative_id_window_150_dim_300_sg_hs_vocab.pkl\r\n",
      "5.2G\t../data/creative_id_window_150_dim_400_sg_1_hs_0_embedding.bin\r\n",
      "5.1G\t../data/creative_id_window_150_dim_400_sg_1_hs_0_embedding.npy\r\n",
      "250M\t../data/creative_id_window_150_dim_400_sg_1_hs_0_neural_test_fe_df.feather\r\n",
      "245M\t../data/creative_id_window_150_dim_400_sg_1_hs_0_neural_train_fe_df.feather\r\n",
      "71M\t../data/creative_id_window_150_dim_400_sg_1_hs_0_vocab.pkl\r\n",
      "413M\t../data/download\r\n",
      "28M\t../data/label_round_one_df.feather\r\n",
      "12K\t../data/product_category_window_150_dim_128_sg_1_hs_0_iter_10_embedding.bin\r\n",
      "12K\t../data/product_category_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy\r\n",
      "87M\t../data/product_category_window_150_dim_128_sg_1_hs_0_iter_10_neural_test_fe_df.feather\r\n",
      "99M\t../data/product_category_window_150_dim_128_sg_1_hs_0_iter_10_neural_train_fe_df.feather\r\n",
      "4.0K\t../data/product_category_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl\r\n",
      "1.2G\t../data/raw_test_df.feather\r\n",
      "1.2G\t../data/raw_train_round_one_df.feather\r\n",
      "13G\t../data/tencent_2019_ad_competition_data\r\n",
      "732M\t../data/test\r\n",
      "2.3G\t../data/test_fe_df.feather\r\n",
      "2.1G\t../data/train_fe_df.feather\r\n",
      "637M\t../data/train_preliminary\r\n"
     ]
    }
   ],
   "source": [
    "! du -sh ../data/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1'> 1.feature_engineering</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-27 20:14:10,252 - mlpipeline.feature_engineering.feature_engineering - INFO - feature_engineering_pandas开始\n",
      "2020-05-27 20:14:10,255 - mlpipeline.feature_engineering.feature_engineering - INFO - is_train: True, is_neural_network: True\n",
      "2020-05-27 20:14:10,256 - mlpipeline.feature_engineering.feature_engineering - INFO - _load_preprocessed_data开始\n",
      "2020-05-27 20:14:11,351 - mlpipeline.feature_engineering.feature_engineering - INFO - _load_preprocessed_data已完成，共用时0:00:01\n"
     ]
    }
   ],
   "source": [
    "# feature engineering\n",
    "params = {\n",
    "    'train_preprocessed_data_filename':'raw_train_round_one_df.feather', \n",
    "    'test_preprocessed_data_filename':'raw_test_df.feather', \n",
    "    'train_fe_save_filename': 'neural_train_fe_df.feather',\n",
    "    'test_fe_save_filename': 'neural_test_fe_df.feather',\n",
    "    'emb_method':'w2v',\n",
    "    'max_df':0.9,  # param for tf_idf\n",
    "    'min_df':3,  # param for tf_idf\n",
    "    'emb_dim':128,  \n",
    "    'window':150,  \n",
    "    'sparse_feat':'advertise_id',  # advertiser_id, product_category, \n",
    "    'min_count':1, \n",
    "#     'sample':6e-5, \n",
    "#     'negative':0,  \n",
    "    'hs':0, \n",
    "#     'alpha':0.03,\n",
    "#     'min_alpha':0.0007,\n",
    "    'iter_':10,\n",
    "    'workers':20,\n",
    "    'sg':1,\n",
    "    'num_processes': 40,\n",
    "    'is_train':True,\n",
    "    'is_neural_network':True\n",
    "}\n",
    "\n",
    "train_fe_df, test_fe_df = feature_engineering_wrapper(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-28 15:07:51,383 - mlpipeline.train - INFO - train开始\n",
      "2020-05-28 15:07:51,386 - mlpipeline.train - INFO - using_fe_df: creative_advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_train_fe_df.feather, use_label: y, is_eval: True, model_type: neural, model_name: bilstm_attention, use_log: False, use_std: False, use_cv: True, n_splits: 2\n",
      "2020-05-28 15:07:52,702 - mlpipeline.train - INFO - _train_pipeline_neural开始\n",
      "2020-05-28 15:07:56,288 - mlpipeline.train - INFO - 模型参数: {'model_name': 'bilstm_attention', 'num_classes': 20, 'sparse_feat': ['creative_id', 'advertiser_id'], 'embed': ['creative_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy', 'advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy'], 'vocab_paths': ['creative_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl', 'advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl'], 'dropout': 0.3, 'required_improvement': 1000, 'num_epochs': 20, 'batch_size': 128, 'learning_rate': 0.001, 'hidden_size': 128, 'use_pad': True, 'max_seq_len': 90, 'seed': 1234, 'init_method': 'xavier', 'num_layers': 1, 'bidirectional': True}\n",
      "2020-05-28 15:07:56,290 - mlpipeline.train - INFO - _get_cv_folds开始\n",
      "2020-05-28 15:07:56,292 - mlpipeline.train - INFO - _get_cv_folds已完成，共用时0:00:00\n",
      "2020-05-28 15:07:57,030 - utils.utils - INFO - build_dataset开始\n",
      "2020-05-28 15:07:59,108 - utils.utils - INFO - ../data/creative_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl has been loaded\n",
      "2020-05-28 15:07:59,128 - utils.utils - INFO - ../data/advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl has been loaded\n",
      "2020-05-28 15:10:12,883 - utils.utils - INFO - build_dataset已完成，共用时0:02:16\n",
      "2020-05-28 15:10:12,885 - mlpipeline.train - INFO - Loading data...\n",
      "2020-05-28 15:10:12,886 - utils.utils - INFO - build_iterater开始\n",
      "2020-05-28 15:10:12,886 - utils.utils - INFO - build_iterater已完成，共用时0:00:00\n",
      "2020-05-28 15:10:12,887 - utils.utils - INFO - build_iterater开始\n",
      "2020-05-28 15:10:12,888 - utils.utils - INFO - build_iterater已完成，共用时0:00:00\n",
      "2020-05-28 15:10:12,889 - mlpipeline.train - INFO - Time usage:0:00:00\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "2020-05-28 15:10:17,976 - utils.utils - INFO - init_network开始\n",
      "2020-05-28 15:10:17,978 - utils.utils - INFO - init_network已完成，共用时0:00:00\n",
      "2020-05-28 15:10:17,979 - utils.utils - INFO - neural_train开始\n",
      "2020-05-28 15:10:17,982 - utils.utils - INFO - Epoch [1/20]\n",
      "2020-05-28 15:11:43,041 - utils.utils - INFO - Iter:      0,  Train Loss:   3.0,  Train Acc:  0.00%,  Val Loss:   3.0,  Val Acc:  5.73%,  Time: 0:01:25 *\n",
      "2020-05-28 15:13:21,449 - utils.utils - INFO - Iter:    100,  Train Loss:   1.9,  Train Acc: 25.00%,  Val Loss:   1.9,  Val Acc: 29.74%,  Time: 0:03:03 *\n",
      "2020-05-28 15:14:57,591 - utils.utils - INFO - Iter:    200,  Train Loss:   1.8,  Train Acc: 26.56%,  Val Loss:   1.8,  Val Acc: 34.10%,  Time: 0:04:40 *\n",
      "2020-05-28 15:16:34,916 - utils.utils - INFO - Iter:    300,  Train Loss:   1.8,  Train Acc: 35.16%,  Val Loss:   1.7,  Val Acc: 35.25%,  Time: 0:06:17 *\n",
      "2020-05-28 15:18:14,798 - utils.utils - INFO - Iter:    400,  Train Loss:   1.7,  Train Acc: 33.59%,  Val Loss:   1.7,  Val Acc: 37.27%,  Time: 0:07:57 *\n",
      "2020-05-28 15:19:48,228 - utils.utils - INFO - Iter:    500,  Train Loss:   1.7,  Train Acc: 31.25%,  Val Loss:   1.6,  Val Acc: 37.87%,  Time: 0:09:30 *\n",
      "2020-05-28 15:21:21,163 - utils.utils - INFO - Iter:    600,  Train Loss:   1.7,  Train Acc: 33.59%,  Val Loss:   1.6,  Val Acc: 38.08%,  Time: 0:11:03 *\n",
      "2020-05-28 15:22:52,024 - utils.utils - INFO - Iter:    700,  Train Loss:   1.7,  Train Acc: 43.75%,  Val Loss:   1.6,  Val Acc: 38.42%,  Time: 0:12:34 *\n",
      "2020-05-28 15:24:22,647 - utils.utils - INFO - Iter:    800,  Train Loss:   1.8,  Train Acc: 37.50%,  Val Loss:   1.6,  Val Acc: 38.97%,  Time: 0:14:05 *\n",
      "2020-05-28 15:25:37,340 - utils.utils - INFO - Iter:    900,  Train Loss:   1.8,  Train Acc: 37.50%,  Val Loss:   1.6,  Val Acc: 38.74%,  Time: 0:15:19 \n",
      "2020-05-28 15:26:52,225 - utils.utils - INFO - Iter:   1000,  Train Loss:   1.6,  Train Acc: 45.31%,  Val Loss:   1.6,  Val Acc: 38.55%,  Time: 0:16:34 \n",
      "2020-05-28 15:28:23,938 - utils.utils - INFO - Iter:   1100,  Train Loss:   1.6,  Train Acc: 37.50%,  Val Loss:   1.6,  Val Acc: 39.57%,  Time: 0:18:06 *\n",
      "2020-05-28 15:29:54,498 - utils.utils - INFO - Iter:   1200,  Train Loss:   1.6,  Train Acc: 33.59%,  Val Loss:   1.6,  Val Acc: 39.67%,  Time: 0:19:37 *\n",
      "2020-05-28 15:31:22,644 - utils.utils - INFO - Iter:   1300,  Train Loss:   1.5,  Train Acc: 48.44%,  Val Loss:   1.6,  Val Acc: 39.93%,  Time: 0:21:05 *\n",
      "2020-05-28 15:32:37,354 - utils.utils - INFO - Iter:   1400,  Train Loss:   1.5,  Train Acc: 39.06%,  Val Loss:   1.6,  Val Acc: 39.97%,  Time: 0:22:19 \n",
      "2020-05-28 15:33:51,220 - utils.utils - INFO - Iter:   1500,  Train Loss:   1.8,  Train Acc: 40.62%,  Val Loss:   1.6,  Val Acc: 39.90%,  Time: 0:23:33 \n",
      "2020-05-28 15:35:23,298 - utils.utils - INFO - Iter:   1600,  Train Loss:   1.6,  Train Acc: 35.16%,  Val Loss:   1.6,  Val Acc: 39.98%,  Time: 0:25:05 *\n",
      "2020-05-28 15:36:54,177 - utils.utils - INFO - Iter:   1700,  Train Loss:   1.7,  Train Acc: 40.62%,  Val Loss:   1.6,  Val Acc: 40.14%,  Time: 0:26:36 *\n",
      "2020-05-28 15:38:24,261 - utils.utils - INFO - Iter:   1800,  Train Loss:   1.6,  Train Acc: 43.75%,  Val Loss:   1.6,  Val Acc: 40.26%,  Time: 0:28:06 *\n",
      "2020-05-28 15:39:56,949 - utils.utils - INFO - Iter:   1900,  Train Loss:   1.5,  Train Acc: 46.88%,  Val Loss:   1.6,  Val Acc: 40.36%,  Time: 0:29:39 *\n",
      "2020-05-28 15:41:26,049 - utils.utils - INFO - Iter:   2000,  Train Loss:   1.6,  Train Acc: 40.62%,  Val Loss:   1.6,  Val Acc: 40.44%,  Time: 0:31:08 *\n",
      "2020-05-28 15:42:57,985 - utils.utils - INFO - Iter:   2100,  Train Loss:   1.5,  Train Acc: 42.97%,  Val Loss:   1.6,  Val Acc: 40.65%,  Time: 0:32:40 *\n",
      "2020-05-28 15:44:12,354 - utils.utils - INFO - Iter:   2200,  Train Loss:   1.6,  Train Acc: 39.84%,  Val Loss:   1.6,  Val Acc: 39.26%,  Time: 0:33:54 \n",
      "2020-05-28 15:45:26,530 - utils.utils - INFO - Iter:   2300,  Train Loss:   1.6,  Train Acc: 32.81%,  Val Loss:   1.6,  Val Acc: 40.61%,  Time: 0:35:09 \n",
      "2020-05-28 15:46:39,959 - utils.utils - INFO - Iter:   2400,  Train Loss:   1.6,  Train Acc: 38.28%,  Val Loss:   1.6,  Val Acc: 40.47%,  Time: 0:36:22 \n",
      "2020-05-28 15:47:53,878 - utils.utils - INFO - Iter:   2500,  Train Loss:   1.5,  Train Acc: 39.84%,  Val Loss:   1.6,  Val Acc: 40.61%,  Time: 0:37:36 \n",
      "2020-05-28 15:49:28,970 - utils.utils - INFO - Iter:   2600,  Train Loss:   1.6,  Train Acc: 37.50%,  Val Loss:   1.5,  Val Acc: 41.19%,  Time: 0:39:11 *\n",
      "2020-05-28 15:50:43,968 - utils.utils - INFO - Iter:   2700,  Train Loss:   1.6,  Train Acc: 35.16%,  Val Loss:   1.6,  Val Acc: 40.77%,  Time: 0:40:26 \n",
      "2020-05-28 15:51:58,416 - utils.utils - INFO - Iter:   2800,  Train Loss:   1.7,  Train Acc: 44.53%,  Val Loss:   1.5,  Val Acc: 40.97%,  Time: 0:41:40 \n",
      "2020-05-28 15:53:12,723 - utils.utils - INFO - Iter:   2900,  Train Loss:   1.5,  Train Acc: 42.19%,  Val Loss:   1.5,  Val Acc: 40.80%,  Time: 0:42:55 \n",
      "2020-05-28 15:54:26,333 - utils.utils - INFO - Iter:   3000,  Train Loss:   1.6,  Train Acc: 35.94%,  Val Loss:   1.6,  Val Acc: 40.98%,  Time: 0:44:08 \n",
      "2020-05-28 15:55:40,766 - utils.utils - INFO - Iter:   3100,  Train Loss:   1.5,  Train Acc: 39.84%,  Val Loss:   1.5,  Val Acc: 41.08%,  Time: 0:45:23 \n",
      "2020-05-28 15:56:54,539 - utils.utils - INFO - Iter:   3200,  Train Loss:   1.5,  Train Acc: 46.88%,  Val Loss:   1.5,  Val Acc: 40.90%,  Time: 0:46:37 \n",
      "2020-05-28 15:58:22,477 - utils.utils - INFO - Iter:   3300,  Train Loss:   1.6,  Train Acc: 35.94%,  Val Loss:   1.5,  Val Acc: 41.51%,  Time: 0:48:04 *\n",
      "2020-05-28 15:59:37,777 - utils.utils - INFO - Iter:   3400,  Train Loss:   1.7,  Train Acc: 41.41%,  Val Loss:   1.5,  Val Acc: 41.34%,  Time: 0:49:20 \n",
      "2020-05-28 16:01:11,026 - utils.utils - INFO - Iter:   3500,  Train Loss:   1.6,  Train Acc: 39.84%,  Val Loss:   1.5,  Val Acc: 41.67%,  Time: 0:50:53 *\n",
      "2020-05-28 16:01:12,155 - utils.utils - INFO - Epoch [2/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-28 16:02:25,138 - utils.utils - INFO - Iter:   3600,  Train Loss:   1.6,  Train Acc: 42.19%,  Val Loss:   1.5,  Val Acc: 41.52%,  Time: 0:52:07 \n",
      "2020-05-28 16:03:39,017 - utils.utils - INFO - Iter:   3700,  Train Loss:   1.5,  Train Acc: 43.75%,  Val Loss:   1.5,  Val Acc: 41.52%,  Time: 0:53:21 \n",
      "2020-05-28 16:04:52,888 - utils.utils - INFO - Iter:   3800,  Train Loss:   1.4,  Train Acc: 48.44%,  Val Loss:   1.5,  Val Acc: 41.75%,  Time: 0:54:35 \n",
      "2020-05-28 16:06:25,596 - utils.utils - INFO - Iter:   3900,  Train Loss:   1.4,  Train Acc: 47.66%,  Val Loss:   1.5,  Val Acc: 41.97%,  Time: 0:56:08 *\n",
      "2020-05-28 16:07:40,608 - utils.utils - INFO - Iter:   4000,  Train Loss:   1.6,  Train Acc: 41.41%,  Val Loss:   1.5,  Val Acc: 41.47%,  Time: 0:57:23 \n",
      "2020-05-28 16:08:54,694 - utils.utils - INFO - Iter:   4100,  Train Loss:   1.6,  Train Acc: 39.84%,  Val Loss:   1.5,  Val Acc: 41.86%,  Time: 0:58:37 \n",
      "2020-05-28 16:10:09,699 - utils.utils - INFO - Iter:   4200,  Train Loss:   1.4,  Train Acc: 48.44%,  Val Loss:   1.5,  Val Acc: 41.75%,  Time: 0:59:52 \n",
      "2020-05-28 16:11:43,377 - utils.utils - INFO - Iter:   4300,  Train Loss:   1.6,  Train Acc: 36.72%,  Val Loss:   1.5,  Val Acc: 41.93%,  Time: 1:01:25 *\n",
      "2020-05-28 16:13:19,701 - utils.utils - INFO - Iter:   4400,  Train Loss:   1.8,  Train Acc: 35.16%,  Val Loss:   1.5,  Val Acc: 41.90%,  Time: 1:03:02 *\n",
      "2020-05-28 16:14:34,087 - utils.utils - INFO - Iter:   4500,  Train Loss:   1.5,  Train Acc: 41.41%,  Val Loss:   1.5,  Val Acc: 41.90%,  Time: 1:04:16 \n",
      "2020-05-28 16:16:09,272 - utils.utils - INFO - Iter:   4600,  Train Loss:   1.5,  Train Acc: 41.41%,  Val Loss:   1.5,  Val Acc: 42.07%,  Time: 1:05:51 *\n",
      "2020-05-28 16:17:23,843 - utils.utils - INFO - Iter:   4700,  Train Loss:   1.5,  Train Acc: 39.06%,  Val Loss:   1.5,  Val Acc: 41.64%,  Time: 1:07:06 \n",
      "2020-05-28 16:18:37,728 - utils.utils - INFO - Iter:   4800,  Train Loss:   1.5,  Train Acc: 44.53%,  Val Loss:   1.5,  Val Acc: 41.90%,  Time: 1:08:20 \n",
      "2020-05-28 16:19:52,447 - utils.utils - INFO - Iter:   4900,  Train Loss:   1.6,  Train Acc: 39.84%,  Val Loss:   1.5,  Val Acc: 42.14%,  Time: 1:09:34 \n",
      "2020-05-28 16:21:06,986 - utils.utils - INFO - Iter:   5000,  Train Loss:   1.5,  Train Acc: 42.19%,  Val Loss:   1.5,  Val Acc: 41.79%,  Time: 1:10:49 \n",
      "2020-05-28 16:22:21,736 - utils.utils - INFO - Iter:   5100,  Train Loss:   1.5,  Train Acc: 42.19%,  Val Loss:   1.5,  Val Acc: 41.77%,  Time: 1:12:04 \n",
      "2020-05-28 16:23:37,328 - utils.utils - INFO - Iter:   5200,  Train Loss:   1.5,  Train Acc: 43.75%,  Val Loss:   1.5,  Val Acc: 41.95%,  Time: 1:13:19 \n",
      "2020-05-28 16:25:15,194 - utils.utils - INFO - Iter:   5300,  Train Loss:   1.6,  Train Acc: 42.19%,  Val Loss:   1.5,  Val Acc: 42.05%,  Time: 1:14:57 *\n",
      "2020-05-28 16:26:47,751 - utils.utils - INFO - Iter:   5400,  Train Loss:   1.4,  Train Acc: 49.22%,  Val Loss:   1.5,  Val Acc: 42.18%,  Time: 1:16:30 *\n",
      "2020-05-28 16:28:02,363 - utils.utils - INFO - Iter:   5500,  Train Loss:   1.5,  Train Acc: 47.66%,  Val Loss:   1.5,  Val Acc: 42.02%,  Time: 1:17:44 \n",
      "2020-05-28 16:29:17,164 - utils.utils - INFO - Iter:   5600,  Train Loss:   1.4,  Train Acc: 44.53%,  Val Loss:   1.5,  Val Acc: 41.90%,  Time: 1:18:59 \n",
      "2020-05-28 16:30:31,708 - utils.utils - INFO - Iter:   5700,  Train Loss:   1.5,  Train Acc: 45.31%,  Val Loss:   1.5,  Val Acc: 42.15%,  Time: 1:20:14 \n",
      "2020-05-28 16:32:02,295 - utils.utils - INFO - Iter:   5800,  Train Loss:   1.5,  Train Acc: 39.84%,  Val Loss:   1.5,  Val Acc: 42.45%,  Time: 1:21:44 *\n",
      "2020-05-28 16:33:17,636 - utils.utils - INFO - Iter:   5900,  Train Loss:   1.5,  Train Acc: 34.38%,  Val Loss:   1.5,  Val Acc: 42.03%,  Time: 1:23:00 \n",
      "2020-05-28 16:34:32,508 - utils.utils - INFO - Iter:   6000,  Train Loss:   1.6,  Train Acc: 37.50%,  Val Loss:   1.5,  Val Acc: 42.15%,  Time: 1:24:15 \n",
      "2020-05-28 16:36:07,404 - utils.utils - INFO - Iter:   6100,  Train Loss:   1.5,  Train Acc: 34.38%,  Val Loss:   1.5,  Val Acc: 42.25%,  Time: 1:25:49 *\n",
      "2020-05-28 16:37:22,085 - utils.utils - INFO - Iter:   6200,  Train Loss:   1.4,  Train Acc: 36.72%,  Val Loss:   1.5,  Val Acc: 42.18%,  Time: 1:27:04 \n",
      "2020-05-28 16:38:37,294 - utils.utils - INFO - Iter:   6300,  Train Loss:   1.5,  Train Acc: 49.22%,  Val Loss:   1.5,  Val Acc: 42.52%,  Time: 1:28:19 \n",
      "2020-05-28 16:40:09,427 - utils.utils - INFO - Iter:   6400,  Train Loss:   1.4,  Train Acc: 44.53%,  Val Loss:   1.5,  Val Acc: 42.64%,  Time: 1:29:51 *\n",
      "2020-05-28 16:41:28,418 - utils.utils - INFO - Iter:   6500,  Train Loss:   1.3,  Train Acc: 48.44%,  Val Loss:   1.5,  Val Acc: 42.62%,  Time: 1:31:10 \n",
      "2020-05-28 16:42:44,093 - utils.utils - INFO - Iter:   6600,  Train Loss:   1.3,  Train Acc: 52.34%,  Val Loss:   1.5,  Val Acc: 42.58%,  Time: 1:32:26 \n",
      "2020-05-28 16:43:59,625 - utils.utils - INFO - Iter:   6700,  Train Loss:   1.6,  Train Acc: 39.06%,  Val Loss:   1.5,  Val Acc: 42.10%,  Time: 1:33:42 \n",
      "2020-05-28 16:45:29,850 - utils.utils - INFO - Iter:   6800,  Train Loss:   1.5,  Train Acc: 39.84%,  Val Loss:   1.5,  Val Acc: 42.58%,  Time: 1:35:12 *\n",
      "2020-05-28 16:46:45,039 - utils.utils - INFO - Iter:   6900,  Train Loss:   1.5,  Train Acc: 38.28%,  Val Loss:   1.5,  Val Acc: 42.53%,  Time: 1:36:27 \n",
      "2020-05-28 16:47:59,572 - utils.utils - INFO - Iter:   7000,  Train Loss:   1.5,  Train Acc: 46.88%,  Val Loss:   1.5,  Val Acc: 42.39%,  Time: 1:37:42 \n",
      "2020-05-28 16:48:01,789 - utils.utils - INFO - Epoch [3/20]\n",
      "2020-05-28 16:49:12,804 - utils.utils - INFO - Iter:   7100,  Train Loss:   1.6,  Train Acc: 39.84%,  Val Loss:   1.5,  Val Acc: 42.36%,  Time: 1:38:55 \n",
      "2020-05-28 16:50:27,032 - utils.utils - INFO - Iter:   7200,  Train Loss:   1.3,  Train Acc: 47.66%,  Val Loss:   1.5,  Val Acc: 42.35%,  Time: 1:40:09 \n",
      "2020-05-28 16:51:57,886 - utils.utils - INFO - Iter:   7300,  Train Loss:   1.6,  Train Acc: 41.41%,  Val Loss:   1.5,  Val Acc: 42.61%,  Time: 1:41:40 *\n",
      "2020-05-28 16:53:12,971 - utils.utils - INFO - Iter:   7400,  Train Loss:   1.7,  Train Acc: 38.28%,  Val Loss:   1.5,  Val Acc: 42.63%,  Time: 1:42:55 \n",
      "2020-05-28 16:54:27,030 - utils.utils - INFO - Iter:   7500,  Train Loss:   1.5,  Train Acc: 36.72%,  Val Loss:   1.5,  Val Acc: 42.12%,  Time: 1:44:09 \n",
      "2020-05-28 16:55:41,892 - utils.utils - INFO - Iter:   7600,  Train Loss:   1.4,  Train Acc: 44.53%,  Val Loss:   1.5,  Val Acc: 42.54%,  Time: 1:45:24 \n",
      "2020-05-28 16:56:56,293 - utils.utils - INFO - Iter:   7700,  Train Loss:   1.4,  Train Acc: 42.19%,  Val Loss:   1.5,  Val Acc: 42.59%,  Time: 1:46:38 \n",
      "2020-05-28 16:58:10,161 - utils.utils - INFO - Iter:   7800,  Train Loss:   1.5,  Train Acc: 47.66%,  Val Loss:   1.5,  Val Acc: 42.49%,  Time: 1:47:52 \n",
      "2020-05-28 16:59:41,545 - utils.utils - INFO - Iter:   7900,  Train Loss:   1.6,  Train Acc: 41.41%,  Val Loss:   1.5,  Val Acc: 42.87%,  Time: 1:49:24 *\n",
      "2020-05-28 17:00:58,178 - utils.utils - INFO - Iter:   8000,  Train Loss:   1.5,  Train Acc: 41.41%,  Val Loss:   1.5,  Val Acc: 42.73%,  Time: 1:50:40 \n",
      "2020-05-28 17:03:20,673 - utils.utils - INFO - Iter:   8100,  Train Loss:   1.7,  Train Acc: 39.06%,  Val Loss:   1.5,  Val Acc: 42.52%,  Time: 1:53:03 \n",
      "2020-05-28 17:05:50,089 - utils.utils - INFO - Iter:   8200,  Train Loss:   1.5,  Train Acc: 35.16%,  Val Loss:   1.5,  Val Acc: 42.44%,  Time: 1:55:32 \n",
      "2020-05-28 17:08:16,135 - utils.utils - INFO - Iter:   8300,  Train Loss:   1.6,  Train Acc: 45.31%,  Val Loss:   1.5,  Val Acc: 42.48%,  Time: 1:57:58 \n",
      "2020-05-28 17:10:41,412 - utils.utils - INFO - Iter:   8400,  Train Loss:   1.6,  Train Acc: 37.50%,  Val Loss:   1.5,  Val Acc: 42.89%,  Time: 2:00:23 \n",
      "2020-05-28 17:13:03,144 - utils.utils - INFO - Iter:   8500,  Train Loss:   1.4,  Train Acc: 42.19%,  Val Loss:   1.5,  Val Acc: 42.77%,  Time: 2:02:45 \n",
      "2020-05-28 17:15:41,034 - utils.utils - INFO - Iter:   8600,  Train Loss:   1.3,  Train Acc: 50.78%,  Val Loss:   1.5,  Val Acc: 42.88%,  Time: 2:05:23 *\n",
      "2020-05-28 17:18:03,786 - utils.utils - INFO - Iter:   8700,  Train Loss:   1.6,  Train Acc: 35.94%,  Val Loss:   1.5,  Val Acc: 42.61%,  Time: 2:07:46 \n",
      "2020-05-28 17:20:29,568 - utils.utils - INFO - Iter:   8800,  Train Loss:   1.6,  Train Acc: 42.19%,  Val Loss:   1.5,  Val Acc: 42.32%,  Time: 2:10:12 \n"
     ]
    }
   ],
   "source": [
    "# eval \n",
    "# lgb_model_params = {\n",
    "#                'objective': 'multiclass',  # multiclass, binary \n",
    "#                'boosting': 'gbdt',\n",
    "#                'learning_rate': 0.15,\n",
    "#                'metric': ['multi_logloss'],  # 'binary_logloss', 'multi_logloss'\n",
    "#                'num_threads': 20,\n",
    "#                'random_state': 2019,\n",
    "#                'num_boost_round': 1000,\n",
    "#                'device': 'cpu',\n",
    "#                'num_class':20,  # 2, 20 ,10\n",
    "#                'num_leaves':32,  # [16,32,64,128]\n",
    "#                'subsample': 0.9,  # [0.7,0.8,0.9,1]\n",
    "#                'colsample_bytree': 0.9, # [0.2,0.3,0.4,0.5,0.6]\n",
    "#                'min_data_in_leaf': 40, # [20,40,60,80,100]\n",
    "#                'lambda_l1': 1.0,  # (0.2,3)\n",
    "#                'lambda_l2': 1.0,  # (0.2,3)\n",
    "# }\n",
    "\n",
    "# 0.3903862863136468, 0.39146038751369455\n",
    "# xgb_model_params = {\n",
    "#                'objective': 'multi:softmax',  # multiclass, binary \n",
    "#                'booster': 'gbtree',\n",
    "#                'eta': 0.15,\n",
    "#                'eval_metric': ['mlogloss'],  # 'binary_logloss', 'multi_logloss'\n",
    "#                'nthread': 15,\n",
    "#                'random_state': 2019,\n",
    "#                'tree_method':'auto',\n",
    "#                'n_estimators': 2,\n",
    "#                'device': 'cpu',\n",
    "#                'num_class':20,  # 2, 20 ,10\n",
    "#                'max_leaves':32,  # [16,32,64,128]\n",
    "#                'subsample': 0.9,  # [0.7,0.8,0.9,1]\n",
    "#                'colsample_bytree': 0.9, # [0.2,0.3,0.4,0.5,0.6]\n",
    "#                'min_data_in_leaf': 40, # [20,40,60,80,100]\n",
    "#                'reg_lambda': 1.0,  # (0.2,3)\n",
    "#                'reg_alpha': 1.0,  # (0.2,3)\n",
    "# }\n",
    "# lstm_model_params ={\n",
    "#     'model_name':'lstm', \n",
    "#     'num_classes':20, \n",
    "#     'sparse_feat':'creative_id', \n",
    "#     'embed':'embedding_creative_id_window_150_dim_300_sg_hs_w2v.npy',\n",
    "#     'dropout':0.2,\n",
    "#     'required_improvement':1000,\n",
    "#     'num_epochs':3,\n",
    "#     'batch_size':128,\n",
    "#     'learning_rate':1e-3,\n",
    "#     'hidden_size':128,\n",
    "#     'use_pad':True,\n",
    "#     'max_seq_len':110,\n",
    "#     'seed':1234,\n",
    "#     'init_method':'xavier' , # 'kaiming'\n",
    "#     'num_layers' : 1,\n",
    "#     'bidirectional':False\n",
    "# }\n",
    "\n",
    "# textcnn_model_params={\n",
    "#     'model_name':'textcnn', \n",
    "#     'num_classes':20, \n",
    "#     'sparse_feat':'creative_id', \n",
    "#     'embed':'embedding_creative_id_300.npy',\n",
    "#     'dropout':0.2,\n",
    "#     'required_improvement':1000,\n",
    "#     'num_epochs':20,\n",
    "#     'batch_size':128,\n",
    "#     'learning_rate':1e-3,\n",
    "#     'filter_size':[3,5,7],\n",
    "#     'num_filters':3,\n",
    "#     'use_pad':True,\n",
    "#     'pad_size':64,\n",
    "# }\n",
    "\n",
    "# transformer_model_params = {\n",
    "#     'model_name':'transformer',\n",
    "#     'num_classes':20,\n",
    "#     'sparse_feat':'creative_id', \n",
    "#     'embed':'embedding_creative_id_300.npy',\n",
    "#     'dropout':0.2,\n",
    "#     'required_improvement':1000,\n",
    "#     'num_epochs':5,\n",
    "#     'batch_size':128,\n",
    "#     'learning_rate':1e-3,\n",
    "#     'dim_model':300,\n",
    "#     'hidden':1024,\n",
    "#     'last_hidden':512,\n",
    "#     'num_head':5,\n",
    "#     'init_method':'kaiming',\n",
    "#     'num_encoder':2,\n",
    "#     'use_pad':True,\n",
    "#     'seed':1,\n",
    "#     'pad_size':64,\n",
    "# }\n",
    "bilstm_attention_model_params = {\n",
    "    'model_name':'bilstm_attention',\n",
    "    'num_classes':20,\n",
    "    'sparse_feat':[\n",
    "        'creative_id',\n",
    "        'advertiser_id',\n",
    "    ] ,\n",
    "    'embed':[\n",
    "             'creative_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy',\n",
    "             'advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy'\n",
    "    ],\n",
    "    'vocab_paths':[\n",
    "        'creative_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl',\n",
    "        'advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl',\n",
    "    ],\n",
    "    'dropout':0.3,\n",
    "    'required_improvement':1000,\n",
    "    'num_epochs':20,\n",
    "    'batch_size':128,\n",
    "    'learning_rate':1e-3,\n",
    "    'hidden_size':128,\n",
    "    'use_pad':True,\n",
    "    'max_seq_len':90,\n",
    "    'seed':1234,\n",
    "    'init_method':'xavier' , # 'kaiming','xavier'\n",
    "    'num_layers' : 1,\n",
    "#     'attention_size':256,\n",
    "    'bidirectional':True\n",
    "}\n",
    "\n",
    "# lstm_attention_model_params ={\n",
    "#     'model_name':'lstm_attention',\n",
    "#     'num_classes':20,\n",
    "#     'sparse_feat':'creative_id', \n",
    "#     'embed':'embedding_creative_id_300.npy',\n",
    "#     'dropout':0.2,\n",
    "#     'required_improvement':1000,\n",
    "#     'num_epochs':3,\n",
    "#     'batch_size':1,\n",
    "#     'learning_rate':1e-3,\n",
    "#     'hidden_size':256,\n",
    "#     'use_pad':True,\n",
    "#     'seed':1234,\n",
    "#     'init_method':'kaiming' , # 'kaiming', 'xavier'\n",
    "#     'num_layers' : 1,\n",
    "#     'max_seq_len':90,\n",
    "#     'bidirectional':False\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'fe_filename':'creative_advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_train_fe_df.feather', \n",
    "    'is_eval':True, \n",
    "    'model_type': 'neural',\n",
    "    'model_name': 'bilstm_attention',\n",
    "    'model_params': bilstm_attention_model_params,\n",
    "    'use_log': False,\n",
    "    'use_std': False,\n",
    "    'use_cv': True,  \n",
    "    'n_splits':2,\n",
    "}\n",
    "train_wrapper(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-28 14:46:49,545 - mlpipeline.train - INFO - train开始\n",
      "2020-05-28 14:46:49,546 - mlpipeline.train - INFO - using_fe_df: creative_advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_train_fe_df.feather, use_label: y, is_eval: False, model_type: neural, model_name: bilstm_attention, use_log: False, use_std: False, use_cv: False, n_splits: 2\n",
      "2020-05-28 14:46:50,885 - mlpipeline.train - INFO - _train_pipeline_neural开始\n",
      "2020-05-28 14:46:53,731 - mlpipeline.train - INFO - 模型参数: {'model_name': 'bilstm_attention', 'num_classes': 20, 'sparse_feat': ['creative_id', 'advertiser_id'], 'embed': ['creative_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy', 'advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy'], 'vocab_paths': ['creative_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl', 'advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl'], 'dropout': 0.3, 'required_improvement': 1000, 'num_epochs': 5, 'batch_size': 128, 'learning_rate': 0.001, 'hidden_size': 128, 'use_pad': True, 'max_seq_len': 90, 'seed': 1234, 'init_method': 'xavier', 'num_layers': 1, 'bidirectional': True}\n",
      "2020-05-28 14:46:53,794 - utils.utils - INFO - build_dataset开始\n",
      "2020-05-28 14:46:55,611 - utils.utils - INFO - ../data/creative_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl has been loaded\n",
      "2020-05-28 14:46:55,631 - utils.utils - INFO - ../data/advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl has been loaded\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "lstm_model_params ={\n",
    "    'model_name':'lstm', \n",
    "    'num_classes':20, \n",
    "    'sparse_feat':'creative_id', \n",
    "    'embed':'embedding_creative_id_300.npy',\n",
    "    'dropout':0.5,\n",
    "    'required_improvement':1000,\n",
    "    'num_epochs':5,\n",
    "    'batch_size':128,\n",
    "    'learning_rate':1e-3,\n",
    "    'hidden_size':128,\n",
    "    'use_pad':True,\n",
    "    'pad_size':64,\n",
    "    'seed':1234,\n",
    "    'init_method':'kaiming' , # 'kaiming'\n",
    "    'num_layers' : 1,\n",
    "    'bidirectional':True\n",
    "}\n",
    "\n",
    "bilstm_attention_model_params = {\n",
    "    'model_name':'bilstm_attention',\n",
    "    'num_classes':20,\n",
    "    'sparse_feat':[\n",
    "        'creative_id',\n",
    "        'advertiser_id',\n",
    "    ] ,\n",
    "    'embed':[\n",
    "             'creative_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy',\n",
    "             'advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy'\n",
    "    ],\n",
    "    'vocab_paths':[\n",
    "        'creative_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl',\n",
    "        'advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl',\n",
    "    ],\n",
    "    'dropout':0.3,\n",
    "    'required_improvement':1000,\n",
    "    'num_epochs':5,\n",
    "    'batch_size':128,\n",
    "    'learning_rate':1e-3,\n",
    "    'hidden_size':128,\n",
    "    'use_pad':True,\n",
    "    'max_seq_len':90,\n",
    "    'seed':1234,\n",
    "    'init_method':'xavier' , # 'kaiming','xavier'\n",
    "    'num_layers' : 1,\n",
    "#     'attention_size':256,\n",
    "    'bidirectional':True\n",
    "}\n",
    "\n",
    "lstm_attention_model_params ={\n",
    "    'model_name':'lstm_attention',\n",
    "    'num_classes':20,\n",
    "    'sparse_feat':'creative_id', \n",
    "    'embed':'embedding_creative_id_300.npy',\n",
    "    'dropout':0.2,\n",
    "    'required_improvement':1000,\n",
    "    'num_epochs':3,\n",
    "    'batch_size':128,\n",
    "    'learning_rate':1e-3,\n",
    "    'hidden_size':256,\n",
    "    'use_pad':True,\n",
    "    'pad_size':90,\n",
    "    'seed':1234,\n",
    "    'init_method':'kaiming' , # 'kaiming'\n",
    "    'num_layers' : 1,\n",
    "    'max_seq_len':90,\n",
    "    'bidirectional':False\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'fe_filename':'creative_advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_train_fe_df.feather', \n",
    "    'is_eval':False, \n",
    "    'model_type': 'neural',\n",
    "    'model_name': 'bilstm_attention',\n",
    "    'model_params': bilstm_attention_model_params,\n",
    "    'use_log': False,\n",
    "    'use_std': False,\n",
    "    'use_cv': False,  \n",
    "}\n",
    "\n",
    "model = train_wrapper(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-28 14:47:14,777 - mlpipeline.predict - INFO - predict开始\n",
      "2020-05-28 14:47:14,779 - mlpipeline.predict - INFO - test_fe_filename: creative_advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_test_fe_df.feather, use_log: False, use_std: False, model_type: neural, model_name: bilstm_attention\n",
      "2020-05-28 14:47:16,624 - mlpipeline.predict - INFO - inference_pipeline_neural开始\n",
      "2020-05-28 14:47:19,310 - utils.utils - INFO - build_dataset开始\n",
      "2020-05-28 14:47:21,093 - utils.utils - INFO - ../data/creative_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl has been loaded\n",
      "2020-05-28 14:47:21,111 - utils.utils - INFO - ../data/advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl has been loaded\n",
      "2020-05-28 14:49:40,378 - utils.utils - INFO - build_dataset已完成，共用时0:02:21\n",
      "2020-05-28 14:49:40,380 - mlpipeline.predict - INFO - Loading data...\n",
      "2020-05-28 14:49:40,381 - utils.utils - INFO - build_iterater开始\n",
      "2020-05-28 14:49:40,382 - utils.utils - INFO - build_iterater已完成，共用时0:00:00\n",
      "2020-05-28 14:49:40,383 - mlpipeline.predict - INFO - Time usage:0:00:00\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "2020-05-28 14:52:12,866 - mlpipeline.predict - INFO - inference_pipeline_neural已完成，共用时0:04:56\n",
      "2020-05-28 14:52:12,876 - mlpipeline.predict - INFO - _generate_submission_file开始\n",
      "2020-05-28 14:52:20,332 - mlpipeline.predict - INFO - submission file has been stored in ../submission/submission_y_2020-05-28T14:52:14.226609.csv\n",
      "2020-05-28 14:52:20,335 - mlpipeline.predict - INFO - _generate_submission_file已完成，共用时0:00:07\n",
      "2020-05-28 14:52:28,612 - mlpipeline.predict - INFO - predict已完成，共用时0:05:14\n"
     ]
    }
   ],
   "source": [
    "# predict \n",
    "lstm_attention_model_params ={\n",
    "    'model_name':'lstm_attention',\n",
    "    'num_classes':20,\n",
    "    'sparse_feat':'creative_id', \n",
    "    'embed':'embedding_creative_id_300.npy',\n",
    "    'dropout':0.2,\n",
    "    'required_improvement':1000,\n",
    "    'num_epochs':20,\n",
    "    'batch_size':128,\n",
    "    'learning_rate':1e-3,\n",
    "    'hidden_size':256,\n",
    "    'use_pad':True,\n",
    "    'pad_size':90,\n",
    "    'seed':1234,\n",
    "    'init_method':'kaiming' , # 'kaiming'\n",
    "    'num_layers' : 1,\n",
    "    'max_seq_len':90,\n",
    "    'bidirectional':False\n",
    "}\n",
    "\n",
    "\n",
    "bilstm_attention_model_params = {\n",
    "    'model_name':'bilstm_attention',\n",
    "    'num_classes':20,\n",
    "    'sparse_feat':[\n",
    "        'creative_id',\n",
    "        'advertiser_id',\n",
    "    ] ,\n",
    "    'embed':[\n",
    "             'creative_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy',\n",
    "             'advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_embedding.npy'\n",
    "    ],\n",
    "    'vocab_paths':[\n",
    "        'creative_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl',\n",
    "        'advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_vocab.pkl',\n",
    "    ],\n",
    "    'dropout':0.3,\n",
    "    'required_improvement':1000,\n",
    "    'num_epochs':5,\n",
    "    'batch_size':128,\n",
    "    'learning_rate':1e-3,\n",
    "    'hidden_size':128,\n",
    "    'use_pad':True,\n",
    "    'max_seq_len':90,\n",
    "    'seed':1234,\n",
    "    'init_method':'xavier' , # 'kaiming','xavier'\n",
    "    'num_layers' : 1,\n",
    "#     'attention_size':256,\n",
    "    'bidirectional':True\n",
    "}\n",
    "\n",
    "params = {\n",
    "          'test_fe_filename':'creative_advertiser_id_window_150_dim_128_sg_1_hs_0_iter_10_neural_test_fe_df.feather',\n",
    "          'use_log':False,\n",
    "          'use_std': False,\n",
    "          'model_type': 'neural',\n",
    "          'model_name':'bilstm_attention',\n",
    "          'model_params': bilstm_attention_model_params\n",
    "            }\n",
    "\n",
    "submission_df = predict(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predicted_gender</th>\n",
       "      <th>predicted_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3000002</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3000003</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3000004</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3000005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  predicted_gender  predicted_age\n",
       "0  3000001                 1              3\n",
       "1  3000002                 2              7\n",
       "2  3000003                 2              2\n",
       "3  3000004                 1              3\n",
       "4  3000005                 1              3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine age and gender \n",
    "submission_age_df = pd.read_csv(os.path.join(conf.SUBMISSION_DIR,'submission_age_2020-05-28T08:34:08.417593.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predicted_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3000001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3000002</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3000003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3000004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3000005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  predicted_age\n",
       "0  3000001              3\n",
       "1  3000002              7\n",
       "2  3000003              3\n",
       "3  3000004              3\n",
       "4  3000005              4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_age_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_y_df = pd.read_csv(os.path.join(conf.SUBMISSION_DIR,'submission_y_2020-05-23T09:46:08.001373.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predicted_gender</th>\n",
       "      <th>predicted_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3000002</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3000003</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3000004</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3000005</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  predicted_gender  predicted_age\n",
       "0  3000001                 1              3\n",
       "1  3000002                 2              7\n",
       "2  3000003                 2              2\n",
       "3  3000004                 1              3\n",
       "4  3000005                 1              4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_y_df['predicted_age'] = submission_age_df['predicted_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>predicted_gender</th>\n",
       "      <th>predicted_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3000002</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3000003</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3000004</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3000005</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  predicted_gender  predicted_age\n",
       "0  3000001                 1              3\n",
       "1  3000002                 2              7\n",
       "2  3000003                 2              3\n",
       "3  3000004                 1              3\n",
       "4  3000005                 1              4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_save_path = os.path.join(conf.SUBMISSION_DIR,'submission_y_%s.csv'%(datetime.now().isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_y_df.to_csv(os.path.join(conf.SUBMISSION_DIR, submission_save_path),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
