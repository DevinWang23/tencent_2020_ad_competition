{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Do feature engineering \n",
    "- <a href='#1'>1. tf idf </a> \n",
    "- <a href='#2'>2. matrix factorization </a> \n",
    "- <a href='#2'>2. w2v </a> \n",
    "- <a href='#3'>3. stats feat</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.17.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.13.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.17.0,>=1.16.9 in /opt/conda/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.16.9)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.9->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.17.0,>=1.16.9->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os \n",
    "import gc\n",
    "import functools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import multiprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from tqdm import tqdm\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import (\n",
    "    SparkSession,\n",
    "    Window,\n",
    "    DataFrame as Spark_DataFrame\n",
    ")\n",
    "\n",
    "sys.path.append('../')\n",
    "import conf\n",
    "from utils import (\n",
    "    check_columns, \n",
    "    check_nan_value,\n",
    "    correct_column_type_by_value_range,\n",
    "    LogManager,\n",
    "    timer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.width',100)\n",
    "sns.set(rc={'figure.figsize':(11,4)})\n",
    "spark = SparkSession.builder.appName('feature_engineering')\\\n",
    ".config('spark.debug.maxToStringFields',2000)\\\n",
    ".config('spark.num_executor','8')\\\n",
    ".config('spark.executor.memory','15g')\\\n",
    ".config('spark.driver.memory','15g')\\\n",
    ".config('spark.driver.maxResultSize', '10g')\\\n",
    ".config('spark.sql.execution.arrow.enabled',\"true\")\\\n",
    ".getOrCreate()\n",
    "# .config('spark.num_executor','8')\\\n",
    "# .config('spark.executor.memory','2g')\\\n",
    "# .config('spark.driver.memory','10g')\\\n",
    "# .config('spark.master','local[4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEFAULT_MISSING_VALUE = 0\n",
    "FONT = fm.FontProperties(fname = os.path.join(conf.LIB_DIR,'simsun.ttc'))\n",
    "LogManager.created_filename = os.path.join(conf.LOG_DIR, 'feature_engineering.log')\n",
    "logger = LogManager.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def __dummy():\n",
    "    pass\n",
    "\n",
    "def generate_tf_idf_feat(df):\n",
    "    pass\n",
    "\n",
    "def generate_stats_feat():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1'> 1. generate emb for sparse feat</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer(logger)\n",
    "def _generate_emb_for_sparse_feat(\n",
    "    df,\n",
    "    sparse_feat,\n",
    "    method,\n",
    "    max_df=1.0,\n",
    "    min_df=1,\n",
    "    emb_dim=100,\n",
    "    ngram_range = (1,1),\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4,\n",
    "    sg=0\n",
    "):  \n",
    "    sparse_feat_seq_df = df[['user_id',sparse_feat]]\n",
    "    sparse_feat_seq_df[sparse_feat] = sparse_feat_seq_df[sparse_feat].astype(str)\n",
    "    sparse_feat_seq_df = sparse_feat_seq_df.groupby(['user_id'])[sparse_feat].apply(list).reset_index()\n",
    "    \n",
    "    if method == 'tf_idf':\n",
    "        logger.info('sparse_feat: %s , method: %s, emb_dim: %s, max_df: %s, min_df: %s, ngram_range: %s'%(\n",
    "                                                                                  sparse_feat,\n",
    "                                                                                  method,\n",
    "                                                                                  emb_dim,\n",
    "                                                                                  max_df,\n",
    "                                                                                  min_df,\n",
    "                                                                                  ngram_range,\n",
    "    ))  \n",
    "        sparse_feat_seq_df[sparse_feat] = sparse_feat_seq_df[sparse_feat].apply(lambda x:' '.join(x))\n",
    "        tf = TfidfVectorizer(max_features=emb_dim, max_df=max_df, min_df=min_df, sublinear_tf=True,                                     ngram_range=ngram_range)\n",
    "        sparse_feat_seq_arr = tf.fit_transform(sparse_feat_seq_df[sparse_feat].to_list()).toarray()\n",
    "#         logger.info(sparse_feat_seq_arr.shape)\n",
    "#         csr_df = pd.DataFrame.sparse.from_spmatrix(sparse_feat_seq_tf_csr)\n",
    "#         csr_df.columns = ['tf_'+ str(col) for col in csr_df.columns]\n",
    "#         sparse_feat_seq_df = pd.concat([sparse_feat_seq_df[['user_id']], csr_df])\n",
    "    elif method == 'matrix_factorization':\n",
    "        raise NotImplementedError\n",
    "    elif method == 'w2v':\n",
    "        logger.info('sparse_feat: %s , method: %s, emd_dim: %s, window: %s, min_count: %s, workers: %s, sg: %s'%(\n",
    "                                                                                  sparse_feat,\n",
    "                                                                                  method,\n",
    "                                                                                  emb_dim,\n",
    "                                                                                  window,\n",
    "                                                                                  min_count,\n",
    "                                                                                  workers,\n",
    "                                                                                  sg\n",
    "    ))\n",
    "        sparse_feat_seq_list = sparse_feat_seq_df[sparse_feat].to_list()\n",
    "        if os.path.exists(os.path.join(conf.DATA_DIR, '%s_w2v.bin'%sparse_feat)):\n",
    "            w2v_model = KeyedVectors.load_word2vec_format(os.path.join(conf.DATA_DIR, '%s_w2v.bin'%sparse_feat), binary=True) \n",
    "        else:\n",
    "            w2v_model = Word2Vec(\n",
    "                                sparse_feat_seq_list,\n",
    "                                window=window,\n",
    "                                size=emb_dim,\n",
    "                                min_count=min_count,\n",
    "                                workers=workers,\n",
    "                                sg=sg\n",
    "                                )\n",
    "            w2v_model.wv.save_word2vec_format(os.path.join(conf.DATA_DIR, '%s_w2v.bin'%sparse_feat), binary=True)\n",
    "            \n",
    "        sparse_feat_seq_arr = np.asarray([functools.reduce(lambda a,b : a+b, [w2v_model[j] for j in i])/len(i) for i in sparse_feat_seq_list])    \n",
    "    else:\n",
    "        raise NotImplementedError('input method %s out of method range'%method)\n",
    "        \n",
    "    for i in range(1, emb_dim+1):\n",
    "        sparse_feat_seq_df.loc[:,'%s_%s'%(method,i)] = sparse_feat_seq_arr[:,i-1]\n",
    "    \n",
    "    sparse_feat_seq_df.drop(columns=[sparse_feat], inplace=True)\n",
    "#     logger.info(sparse_feat_seq_df.shape)\n",
    "    \n",
    "    return sparse_feat_seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(os.path.join(conf.DATA_DIR, 'creative_id_300_w2v.bin'), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "if '112276' in w2v_model:\n",
    "    print('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed_df = pd.read_feather(os.path.join(conf.DATA_DIR, 'raw_train_round_one_df.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preprocessed_df = pd.read_feather(os.path.join(conf.DATA_DIR, 'raw_test_df.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>click_times</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>industry</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>358946</td>\n",
       "      <td>216469</td>\n",
       "      <td>1</td>\n",
       "      <td>194447</td>\n",
       "      <td>8826.0</td>\n",
       "      <td>3</td>\n",
       "      <td>30464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>652708</td>\n",
       "      <td>53492</td>\n",
       "      <td>1</td>\n",
       "      <td>49831</td>\n",
       "      <td>26858.0</td>\n",
       "      <td>3</td>\n",
       "      <td>29963</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>866186</td>\n",
       "      <td>220806</td>\n",
       "      <td>1</td>\n",
       "      <td>198186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>18103</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>866186</td>\n",
       "      <td>63440</td>\n",
       "      <td>1</td>\n",
       "      <td>58787</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22885</td>\n",
       "      <td>318.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>672438</td>\n",
       "      <td>20857</td>\n",
       "      <td>1</td>\n",
       "      <td>21792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>22918</td>\n",
       "      <td>319.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  user_id  creative_id  click_times   ad_id  product_id product_category  advertiser_id  \\\n",
       "0     1   358946       216469            1  194447      8826.0                3          30464   \n",
       "1     1   652708        53492            1   49831     26858.0                3          29963   \n",
       "2     1   866186       220806            1  198186         NaN               12          18103   \n",
       "3     1   866186        63440            1   58787        87.0                2          22885   \n",
       "4     1   672438        20857            1   21792         NaN               18          22918   \n",
       "\n",
       "  industry  age  gender   y  \n",
       "0      NaN    6       1  16  \n",
       "1     60.0    4       1  14  \n",
       "2      6.0    5       1  15  \n",
       "3    318.0    5       1  15  \n",
       "4    319.0    5       1  15  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>click_times</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3892830</td>\n",
       "      <td>112276</td>\n",
       "      <td>1</td>\n",
       "      <td>101587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>8371</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3530749</td>\n",
       "      <td>14391</td>\n",
       "      <td>1</td>\n",
       "      <td>15775</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10988</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3711528</td>\n",
       "      <td>208390</td>\n",
       "      <td>1</td>\n",
       "      <td>187259</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10925</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3711528</td>\n",
       "      <td>236102</td>\n",
       "      <td>1</td>\n",
       "      <td>212289</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19056</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3998628</td>\n",
       "      <td>90699</td>\n",
       "      <td>1</td>\n",
       "      <td>82895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>10955</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  user_id  creative_id  click_times   ad_id  product_id product_category  advertiser_id  \\\n",
       "0     1  3892830       112276            1  101587         NaN               18           8371   \n",
       "1     1  3530749        14391            1   15775      1261.0                2          10988   \n",
       "2     1  3711528       208390            1  187259      1261.0                2          10925   \n",
       "3     1  3711528       236102            1  212289      1261.0                2          19056   \n",
       "4     1  3998628        90699            1   82895         NaN               18          10955   \n",
       "\n",
       "  industry  \n",
       "0     54.0  \n",
       "1      6.0  \n",
       "2      6.0  \n",
       "3     98.0  \n",
       "4    238.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_cols, cate_cols, cont_cols, label_cols = check_columns(train_preprocessed_df.dtypes.to_dict())\n",
    "train_preprocessed_df.drop(columns=label_cols, inplace=True)\n",
    "test_user_id = test_preprocessed_df['user_id'].unique()  # for further dividing data into train and test\n",
    "preprocessed_df = pd.concat([train_preprocessed_df[index_cols + cate_cols + cont_cols], \n",
    "                             test_preprocessed_df[index_cols + cate_cols + cont_cols]],\n",
    "                             axis=0)\n",
    "del train_preprocessed_df, test_preprocessed_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>creative_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>product_category</th>\n",
       "      <th>industry</th>\n",
       "      <th>click_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>358946</td>\n",
       "      <td>216469</td>\n",
       "      <td>194447</td>\n",
       "      <td>8826.0</td>\n",
       "      <td>30464</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>652708</td>\n",
       "      <td>53492</td>\n",
       "      <td>49831</td>\n",
       "      <td>26858.0</td>\n",
       "      <td>29963</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>866186</td>\n",
       "      <td>220806</td>\n",
       "      <td>198186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18103</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>866186</td>\n",
       "      <td>63440</td>\n",
       "      <td>58787</td>\n",
       "      <td>87.0</td>\n",
       "      <td>22885</td>\n",
       "      <td>2</td>\n",
       "      <td>318.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>672438</td>\n",
       "      <td>20857</td>\n",
       "      <td>21792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22918</td>\n",
       "      <td>18</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  user_id  creative_id   ad_id  product_id  advertiser_id product_category  industry  \\\n",
       "0     1   358946       216469  194447      8826.0          30464                3       NaN   \n",
       "1     1   652708        53492   49831     26858.0          29963                3      60.0   \n",
       "2     1   866186       220806  198186         NaN          18103               12       6.0   \n",
       "3     1   866186        63440   58787        87.0          22885                2     318.0   \n",
       "4     1   672438        20857   21792         NaN          22918               18     319.0   \n",
       "\n",
       "   click_times  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-15 10:26:13,922 - __main__ - INFO - _generate_emb_for_sparse_feat开始\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "2020-05-15 10:32:24,058 - __main__ - INFO - sparse_feat: creative_id , method: w2v, emd_dim: 100, window: 5, min_count: 1, workers: 20, sg: 1\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "2020-05-15 11:17:46,583 - __main__ - INFO - _generate_emb_for_sparse_feat已完成，共用时0:51:33\n"
     ]
    }
   ],
   "source": [
    "sparse_feat_seq_df = _generate_emb_for_sparse_feat (\n",
    "    preprocessed_df,\n",
    "    'creative_id',\n",
    "    'w2v',\n",
    "    emb_dim=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=20,\n",
    "    sg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900000, 101)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_feat_seq_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 10]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[10 if j in [1,2] else 1 for j in [1,2]  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dfs = dict(tuple(disk_smart_train_and_test_df.groupby(['model','serial_number'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_df(args):\n",
    "    df, index_cols, label_cols, cont_cols, cate_cols = args\n",
    "    return _create_daily_features(df, \n",
    "                                   index_cols, \n",
    "                                   label_cols, \n",
    "                                   cont_cols, \n",
    "                                   cate_cols)\n",
    "\n",
    "def back_fill(sub_df, \n",
    "              back_fill_columns,\n",
    "              freq='D',\n",
    "              start_date=None, \n",
    "              end_date=None):\n",
    "    \"\"\"\n",
    "    fill the missing value of a specific date with its nearest neighbour date,\n",
    "    for rolling window\n",
    "    :param sub_df:\n",
    "    :param back_fill_columns: list of strings - filled with the nearest date data\n",
    "    :param freq: str - frequency for filling missing date\n",
    "    :param start_date: str - user-defined start date for sliding window\n",
    "    :param end_date: str - user_defined end date for sliding window\n",
    "    :return: df : pandas data-frame\n",
    "    \"\"\"\n",
    "    back_fill_columns = [col for col in back_fill_columns if col in sub_df.columns]\n",
    "    sub_df = sub_df.sort_values('dt')\n",
    "    sub_df = sub_df.set_index('dt')\n",
    "    start_date, end_date = sub_df.index[0] if start_date is None else start_date, \\\n",
    "                           sub_df.index[-1] if end_date is None else end_date\n",
    "    date_range = pd.date_range(start_date, end_date, freq=freq)\n",
    "\n",
    "    # back fill missing values\n",
    "    sub_back_df = sub_df[back_fill_columns]\n",
    "    sub_non_back_columns = list(set(sub_df.columns) - set(sub_back_df.columns))\n",
    "    if sub_non_back_columns:\n",
    "        sub_non_back_df = sub_df[sub_non_back_columns]\n",
    "        sub_back_df = sub_back_df.reindex(date_range, method='pad')\n",
    "        sub_non_back_df = sub_non_back_df.reindex(date_range, fill_value=0)\n",
    "        df = pd.concat([sub_back_df, sub_non_back_df], axis=1).reset_index().rename(columns={'index': 'dt'})\n",
    "        return df\n",
    "    else:\n",
    "        return sub_back_df.reindex(date_range, method='pad').reset_index().rename(columns={'index': 'dt'})\n",
    "\n",
    "    \n",
    "def _create_skew_kurt_cv(df, \n",
    "                          cols, \n",
    "                          window_list, \n",
    "                          window_size, \n",
    "                          min_periods,\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    create statistics features about distribution\n",
    "    :param df:\n",
    "    :param cols:\n",
    "    :param window_list:\n",
    "    :param window_size:\n",
    "    :param min_periods:\n",
    "    :param start_index:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for i_window in window_list:\n",
    "        target_df = df[cols].iloc[i_window * window_size:]\n",
    "        df_skew = target_df.rolling(i_window * window_size, min_periods=min_periods).skew()\n",
    "        df_skew.columns = [x + \"_skew_\" + str(i_window * window_size) for x in df_skew.columns]\n",
    "        dfs.append(df_skew)\n",
    "        df_kurt = target_df.rolling(i_window * window_size, min_periods=min_periods).kurt()\n",
    "        df_kurt.columns = [x + \"_kurt_\" + str(i_window * window_size) for x in df_kurt.columns]\n",
    "        dfs.append(df_kurt)\n",
    "        df_cv = (target_df.rolling(i_window * window_size, min_periods=min_periods).std() /\n",
    "                 target_df.rolling(i_window * window_size, min_periods=min_periods).mean())\n",
    "        df_cv.columns = [x + \"_cv_\" + str(i_window * window_size) for x in df_cv.columns]\n",
    "        dfs.append(df_cv)\n",
    "    return dfs    \n",
    "\n",
    "def _create_daily_features(df, \n",
    "                            index_cols,\n",
    "                            label_cols,\n",
    "                            cont_cols,\n",
    "                            cate_cols,\n",
    "                            window_list=[1, 2, 7],\n",
    "                            window_size=7,\n",
    "                            min_periods=1,\n",
    "                            last_period_window=[1]):\n",
    "    \"\"\"\n",
    "    create min, max, mean and std for different sliding window size\n",
    "    :param df:\n",
    "    :param window_list:\n",
    "    :param window_size:\n",
    "    :param min_periods:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert len(cont_cols)>0 and len(index_cols)>0 and len(label_cols)>0, \\\n",
    "    'cont_cols, index_cols and label_cols cannot be empty'\n",
    "    \n",
    "    origin_date = df['dt'].values\n",
    "    back_fill_columns = index_cols + cont_cols\n",
    "    df = back_fill(df, back_fill_columns=back_fill_columns, freq='D')\n",
    "    df_index = df[index_cols + ['dt']]\n",
    "    df_label = df[label_cols]\n",
    "    \n",
    "    if len(cate_cols):\n",
    "        df_cate = df[cate_cols]\n",
    "        dfs = [df_index, df_label, df_cate]\n",
    "    else:\n",
    "        dfs = [df_index, df_label]   \n",
    "    df_sliding_cols = df[cont_cols]\n",
    "    \n",
    "    for i_window in window_list:\n",
    "        target_df = df_sliding_cols\n",
    "        dfs.append((target_df.rolling(i_window * window_size, min_periods=min_periods).min()\n",
    "                    ).rename(\n",
    "            columns=dict(zip(cont_cols, [s + \"_min_%s\" % (i_window * window_size) for s in cont_cols]))))\n",
    "        dfs.append((target_df.rolling(i_window * window_size, min_periods=min_periods).max()\n",
    "                    ).rename(\n",
    "            columns=dict(zip(cont_cols, [s + \"_max_%s\" % (i_window * window_size) for s in cont_cols]))))\n",
    "        dfs.append((target_df.rolling(i_window * window_size, min_periods=min_periods).std()\n",
    "                    ).rename(\n",
    "            columns=dict(zip(cont_cols, [s + \"_std_%s\" % (i_window * window_size) for s in cont_cols]))))\n",
    "        dfs.append((target_df.rolling(i_window * window_size, min_periods=min_periods).mean()\n",
    "                    ).rename(\n",
    "            columns=dict(zip(cont_cols, [s + \"_mean_%s\" % (i_window * window_size) for s in cont_cols]))))\n",
    "\n",
    "    # TODO: the last period value for some columns and diff value \n",
    "    for last_period in last_period_window:\n",
    "        if 0< last_period <= 7:\n",
    "            for col in df_sliding_cols.columns:\n",
    "                dfs.append((df_sliding_cols[[col]].shift(last_period)).rename(\n",
    "                    columns=dict({col: '%s_diff_with_last_period_%s' % (col, last_period)})))\n",
    "\n",
    "    # create skew, kurt and cv features\n",
    "    dfs += _create_skew_kurt_cv(df_sliding_cols, \n",
    "                                 cont_cols, \n",
    "                                 [window_list[-1]],\n",
    "                                 window_size=window_size,\n",
    "                                 min_periods=min_periods,\n",
    "                                 )\n",
    "#   df = pd.concat(dfs, axis=1).fillna(DEFAULT_MISSING_FLOAT)\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "    origin_date_df = df[df.date.isin(origin_date)]\n",
    "    return origin_date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>flag</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>smart_10_normalized</th>\n",
       "      <th>smart_12_normalized</th>\n",
       "      <th>smart_184_normalized</th>\n",
       "      <th>smart_187_normalized</th>\n",
       "      <th>smart_188_normalized</th>\n",
       "      <th>smart_189_normalized</th>\n",
       "      <th>smart_190_normalized</th>\n",
       "      <th>smart_191_normalized</th>\n",
       "      <th>smart_192_normalized</th>\n",
       "      <th>smart_193_normalized</th>\n",
       "      <th>smart_194_normalized</th>\n",
       "      <th>smart_195_normalized</th>\n",
       "      <th>smart_197_normalized</th>\n",
       "      <th>smart_198_normalized</th>\n",
       "      <th>smart_199_normalized</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>smart_4_normalized</th>\n",
       "      <th>smart_5_normalized</th>\n",
       "      <th>smart_7_normalized</th>\n",
       "      <th>smart_9_normalized</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>disk_115552</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>disk_115560</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>disk_115561</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-26</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>disk_115563</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>disk_115563</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt flag manufacturer  model serial_number  smart_10_normalized  smart_12_normalized  \\\n",
       "0 2018-04-06    0            A      1   disk_115552                100.0                100.0   \n",
       "1 2018-04-09    0            A      1   disk_115560                100.0                100.0   \n",
       "2 2018-04-04    0            A      1   disk_115561                100.0                100.0   \n",
       "3 2018-04-26    0            A      1   disk_115563                100.0                100.0   \n",
       "4 2018-04-17    0            A      1   disk_115563                100.0                100.0   \n",
       "\n",
       "   smart_184_normalized  smart_187_normalized  smart_188_normalized  smart_189_normalized  \\\n",
       "0                 100.0                 100.0                 100.0                  99.0   \n",
       "1                 100.0                 100.0                 100.0                 100.0   \n",
       "2                 100.0                 100.0                 100.0                  98.0   \n",
       "3                 100.0                 100.0                 100.0                 100.0   \n",
       "4                 100.0                 100.0                 100.0                 100.0   \n",
       "\n",
       "   smart_190_normalized  smart_191_normalized  smart_192_normalized  smart_193_normalized  \\\n",
       "0                  71.0                 100.0                 100.0                 100.0   \n",
       "1                  69.0                 100.0                 100.0                 100.0   \n",
       "2                  69.0                 100.0                 100.0                 100.0   \n",
       "3                  72.0                 100.0                 100.0                 100.0   \n",
       "4                  73.0                 100.0                 100.0                 100.0   \n",
       "\n",
       "   smart_194_normalized  smart_195_normalized  smart_197_normalized  smart_198_normalized  \\\n",
       "0                  29.0                  47.0                 100.0                 100.0   \n",
       "1                  31.0                   9.0                 100.0                 100.0   \n",
       "2                  31.0                  64.0                 100.0                 100.0   \n",
       "3                  28.0                  45.0                 100.0                 100.0   \n",
       "4                  27.0                  47.0                 100.0                 100.0   \n",
       "\n",
       "   smart_199_normalized  smart_1_normalized  smart_3_normalized  smart_4_normalized  \\\n",
       "0                 200.0                80.0                96.0               100.0   \n",
       "1                 200.0                69.0                96.0               100.0   \n",
       "2                 200.0                77.0                96.0               100.0   \n",
       "3                 200.0                78.0                96.0               100.0   \n",
       "4                 200.0                82.0                96.0               100.0   \n",
       "\n",
       "   smart_5_normalized  smart_7_normalized  smart_9_normalized  tag  \n",
       "0               100.0                94.0                60.0  0.0  \n",
       "1               100.0                93.0                61.0  0.0  \n",
       "2               100.0                93.0                61.0  0.0  \n",
       "3               100.0                93.0                66.0  0.0  \n",
       "4               100.0                93.0                67.0  0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk_smart_train_and_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cate_cols, cont_cols, label_cols = check_columns(disk_smart_train_and_test_df.dtypes.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['model', 'serial_number']\n",
    "pool = multiprocessing.Pool(4)\n",
    "result = pool.map_async(_apply_df, [(sub_dfs[key], index_cols, label_cols, cont_cols, cate_cols) \\\n",
    "                                     for key in sub_dfs.keys()])\n",
    "pool.close()\n",
    "fe_df = pd.concat(list(result.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = fe_df>='2018-04-01' \n",
    "mask &= fe_df <= '2018-07-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fe_df = fe_df[mask]\n",
    "test_fe_df = fe_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fe_maj_label_df = train_fe_df[train_fe_df.tag==0] \n",
    "train_fe_maj_label_df = fe_df.sample(frac=0.6,random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_df = pd.read_feather(os.path.join(conf.DATA_DIR,'sample_by_clustering_0.35_fe_df_01_01_round_2_with_cluster_label.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degradation_err_weight</th>\n",
       "      <th>degradation_err_weight_diff_for_last_period_7</th>\n",
       "      <th>degradation_err_weight_max_7</th>\n",
       "      <th>degradation_err_weight_min_7</th>\n",
       "      <th>degradation_err_weight_std_7</th>\n",
       "      <th>dt</th>\n",
       "      <th>err_weight</th>\n",
       "      <th>err_weight_diff_for_last_period_7</th>\n",
       "      <th>err_weight_max_7</th>\n",
       "      <th>err_weight_min_7</th>\n",
       "      <th>err_weight_std_7</th>\n",
       "      <th>flag</th>\n",
       "      <th>model</th>\n",
       "      <th>model_type</th>\n",
       "      <th>seek_err_weight</th>\n",
       "      <th>seek_err_weight_diff_for_last_period_7</th>\n",
       "      <th>seek_err_weight_max_7</th>\n",
       "      <th>seek_err_weight_min_7</th>\n",
       "      <th>seek_err_weight_std_7</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>smart_12raw</th>\n",
       "      <th>smart_12raw_diff_for_last_period_7</th>\n",
       "      <th>smart_12raw_max_7</th>\n",
       "      <th>smart_12raw_min_7</th>\n",
       "      <th>smart_12raw_std_7</th>\n",
       "      <th>smart_184raw</th>\n",
       "      <th>smart_187_normalized</th>\n",
       "      <th>smart_188raw</th>\n",
       "      <th>smart_189_normalized</th>\n",
       "      <th>smart_189_normalized_diff_for_last_period_7</th>\n",
       "      <th>smart_189_normalized_max_7</th>\n",
       "      <th>smart_189_normalized_min_7</th>\n",
       "      <th>smart_189_normalized_std_7</th>\n",
       "      <th>smart_191_normalized</th>\n",
       "      <th>smart_191_normalized_diff_for_last_period_7</th>\n",
       "      <th>smart_191_normalized_max_7</th>\n",
       "      <th>smart_191_normalized_min_7</th>\n",
       "      <th>smart_191_normalized_std_7</th>\n",
       "      <th>smart_192raw</th>\n",
       "      <th>smart_192raw_diff_for_last_period_7</th>\n",
       "      <th>smart_192raw_max_7</th>\n",
       "      <th>smart_192raw_min_7</th>\n",
       "      <th>smart_192raw_std_7</th>\n",
       "      <th>smart_193_normalized</th>\n",
       "      <th>smart_193_normalized_diff_for_last_period_7</th>\n",
       "      <th>smart_193_normalized_max_7</th>\n",
       "      <th>smart_193_normalized_min_7</th>\n",
       "      <th>smart_193_normalized_std_7</th>\n",
       "      <th>smart_194raw</th>\n",
       "      <th>smart_194raw_diff_for_last_period_7</th>\n",
       "      <th>smart_194raw_max_7</th>\n",
       "      <th>smart_194raw_min_7</th>\n",
       "      <th>smart_194raw_std_7</th>\n",
       "      <th>smart_195_normalized</th>\n",
       "      <th>smart_195_normalized_diff_for_last_period_7</th>\n",
       "      <th>smart_195_normalized_max_7</th>\n",
       "      <th>smart_195_normalized_min_7</th>\n",
       "      <th>smart_195_normalized_std_7</th>\n",
       "      <th>smart_197raw</th>\n",
       "      <th>smart_198raw</th>\n",
       "      <th>smart_199raw</th>\n",
       "      <th>smart_199raw_diff_for_last_period_7</th>\n",
       "      <th>smart_199raw_max_7</th>\n",
       "      <th>smart_199raw_min_7</th>\n",
       "      <th>smart_199raw_std_7</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_1_normalized_diff_for_last_period_7</th>\n",
       "      <th>smart_1_normalized_max_7</th>\n",
       "      <th>smart_1_normalized_min_7</th>\n",
       "      <th>smart_1_normalized_std_7</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>smart_3_normalized_diff_for_last_period_7</th>\n",
       "      <th>smart_3_normalized_max_7</th>\n",
       "      <th>smart_3_normalized_min_7</th>\n",
       "      <th>smart_3_normalized_std_7</th>\n",
       "      <th>smart_4raw</th>\n",
       "      <th>smart_4raw_diff_for_last_period_7</th>\n",
       "      <th>smart_4raw_max_7</th>\n",
       "      <th>smart_4raw_min_7</th>\n",
       "      <th>smart_4raw_std_7</th>\n",
       "      <th>smart_5raw</th>\n",
       "      <th>smart_5raw_diff_for_last_period_7</th>\n",
       "      <th>smart_5raw_max_7</th>\n",
       "      <th>smart_5raw_min_7</th>\n",
       "      <th>smart_5raw_slope_for_last_duration_7</th>\n",
       "      <th>smart_5raw_std_7</th>\n",
       "      <th>smart_7_normalized</th>\n",
       "      <th>smart_7_normalized_diff_for_last_period_7</th>\n",
       "      <th>smart_7_normalized_max_7</th>\n",
       "      <th>smart_7_normalized_min_7</th>\n",
       "      <th>smart_7_normalized_std_7</th>\n",
       "      <th>smart_9_normalized</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>34.686664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.686664</td>\n",
       "      <td>34.686664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-09</td>\n",
       "      <td>3.746948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.746948</td>\n",
       "      <td>3.746948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36.639879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.639879</td>\n",
       "      <td>36.639879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>disk_89624</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>35.366899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.366899</td>\n",
       "      <td>35.366899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-09</td>\n",
       "      <td>11.309656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.309656</td>\n",
       "      <td>11.309656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.787716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.787716</td>\n",
       "      <td>39.787716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>disk_143171</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>40.707018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.707018</td>\n",
       "      <td>40.707018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-09</td>\n",
       "      <td>3.436182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.436182</td>\n",
       "      <td>3.436182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.003033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.003033</td>\n",
       "      <td>40.003033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>disk_28506</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31.103376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.103376</td>\n",
       "      <td>31.103376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-09</td>\n",
       "      <td>16.168701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.168701</td>\n",
       "      <td>16.168701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36.974979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.974979</td>\n",
       "      <td>36.974979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>disk_118621</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>33.063739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.063739</td>\n",
       "      <td>33.063739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-09</td>\n",
       "      <td>3.571587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.571587</td>\n",
       "      <td>3.571587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36.171341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.171341</td>\n",
       "      <td>36.171341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>disk_140526</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   degradation_err_weight  degradation_err_weight_diff_for_last_period_7  \\\n",
       "0               34.686664                                            NaN   \n",
       "1               35.366899                                            NaN   \n",
       "2               40.707018                                            NaN   \n",
       "3               31.103376                                            NaN   \n",
       "4               33.063739                                            NaN   \n",
       "\n",
       "   degradation_err_weight_max_7  degradation_err_weight_min_7  degradation_err_weight_std_7  \\\n",
       "0                     34.686664                     34.686664                           NaN   \n",
       "1                     35.366899                     35.366899                           NaN   \n",
       "2                     40.707018                     40.707018                           NaN   \n",
       "3                     31.103376                     31.103376                           NaN   \n",
       "4                     33.063739                     33.063739                           NaN   \n",
       "\n",
       "          dt  err_weight  err_weight_diff_for_last_period_7  err_weight_max_7  err_weight_min_7  \\\n",
       "0 2017-07-09    3.746948                                NaN          3.746948          3.746948   \n",
       "1 2017-07-09   11.309656                                NaN         11.309656         11.309656   \n",
       "2 2017-07-09    3.436182                                NaN          3.436182          3.436182   \n",
       "3 2017-07-09   16.168701                                NaN         16.168701         16.168701   \n",
       "4 2017-07-09    3.571587                                NaN          3.571587          3.571587   \n",
       "\n",
       "   err_weight_std_7  flag  model model_type  seek_err_weight  \\\n",
       "0               NaN     0      1          0        36.639879   \n",
       "1               NaN     0      1          0        39.787716   \n",
       "2               NaN     0      1          0        40.003033   \n",
       "3               NaN     0      2          1        36.974979   \n",
       "4               NaN     0      1          0        36.171341   \n",
       "\n",
       "   seek_err_weight_diff_for_last_period_7  seek_err_weight_max_7  seek_err_weight_min_7  \\\n",
       "0                                     NaN              36.639879              36.639879   \n",
       "1                                     NaN              39.787716              39.787716   \n",
       "2                                     NaN              40.003033              40.003033   \n",
       "3                                     NaN              36.974979              36.974979   \n",
       "4                                     NaN              36.171341              36.171341   \n",
       "\n",
       "   seek_err_weight_std_7 serial_number  smart_12raw  smart_12raw_diff_for_last_period_7  \\\n",
       "0                    NaN    disk_89624         20.0                                 NaN   \n",
       "1                    NaN   disk_143171         12.0                                 NaN   \n",
       "2                    NaN    disk_28506         19.0                                 NaN   \n",
       "3                    NaN   disk_118621          7.0                                 NaN   \n",
       "4                    NaN   disk_140526          6.0                                 NaN   \n",
       "\n",
       "   smart_12raw_max_7  smart_12raw_min_7  smart_12raw_std_7 smart_184raw  smart_187_normalized  \\\n",
       "0               20.0               20.0                NaN          0.0                   0.0   \n",
       "1               12.0               12.0                NaN          0.0                   0.0   \n",
       "2               19.0               19.0                NaN          0.0                   0.0   \n",
       "3                7.0                7.0                NaN          0.0                   0.0   \n",
       "4                6.0                6.0                NaN          0.0                   0.0   \n",
       "\n",
       "  smart_188raw  smart_189_normalized  smart_189_normalized_diff_for_last_period_7  \\\n",
       "0          0.0                   2.0                                          NaN   \n",
       "1          0.0                   0.0                                          NaN   \n",
       "2          0.0                   6.0                                          NaN   \n",
       "3          1.0                   0.0                                          NaN   \n",
       "4          0.0                   0.0                                          NaN   \n",
       "\n",
       "   smart_189_normalized_max_7  smart_189_normalized_min_7  smart_189_normalized_std_7  \\\n",
       "0                         2.0                         2.0                         NaN   \n",
       "1                         0.0                         0.0                         NaN   \n",
       "2                         6.0                         6.0                         NaN   \n",
       "3                         0.0                         0.0                         NaN   \n",
       "4                         0.0                         0.0                         NaN   \n",
       "\n",
       "   smart_191_normalized  smart_191_normalized_diff_for_last_period_7  smart_191_normalized_max_7  \\\n",
       "0                   0.0                                          NaN                         0.0   \n",
       "1                   0.0                                          NaN                         0.0   \n",
       "2                   0.0                                          NaN                         0.0   \n",
       "3                   0.0                                          NaN                         0.0   \n",
       "4                   0.0                                          NaN                         0.0   \n",
       "\n",
       "   smart_191_normalized_min_7  smart_191_normalized_std_7  smart_192raw  \\\n",
       "0                         0.0                         NaN          19.0   \n",
       "1                         0.0                         NaN          11.0   \n",
       "2                         0.0                         NaN          17.0   \n",
       "3                         0.0                         NaN          13.0   \n",
       "4                         0.0                         NaN           5.0   \n",
       "\n",
       "   smart_192raw_diff_for_last_period_7  smart_192raw_max_7  smart_192raw_min_7  \\\n",
       "0                                  NaN                19.0                19.0   \n",
       "1                                  NaN                11.0                11.0   \n",
       "2                                  NaN                17.0                17.0   \n",
       "3                                  NaN                13.0                13.0   \n",
       "4                                  NaN                 5.0                 5.0   \n",
       "\n",
       "   smart_192raw_std_7  smart_193_normalized  smart_193_normalized_diff_for_last_period_7  \\\n",
       "0                 NaN                   0.0                                          NaN   \n",
       "1                 NaN                   0.0                                          NaN   \n",
       "2                 NaN                   0.0                                          NaN   \n",
       "3                 NaN                   0.0                                          NaN   \n",
       "4                 NaN                   0.0                                          NaN   \n",
       "\n",
       "   smart_193_normalized_max_7  smart_193_normalized_min_7  smart_193_normalized_std_7  \\\n",
       "0                         0.0                         0.0                         NaN   \n",
       "1                         0.0                         0.0                         NaN   \n",
       "2                         0.0                         0.0                         NaN   \n",
       "3                         0.0                         0.0                         NaN   \n",
       "4                         0.0                         0.0                         NaN   \n",
       "\n",
       "   smart_194raw  smart_194raw_diff_for_last_period_7  smart_194raw_max_7  smart_194raw_min_7  \\\n",
       "0          28.0                                  NaN                28.0                28.0   \n",
       "1          29.0                                  NaN                29.0                29.0   \n",
       "2          31.0                                  NaN                31.0                31.0   \n",
       "3          29.0                                  NaN                29.0                29.0   \n",
       "4          29.0                                  NaN                29.0                29.0   \n",
       "\n",
       "   smart_194raw_std_7  smart_195_normalized  smart_195_normalized_diff_for_last_period_7  \\\n",
       "0                 NaN                  52.0                                          NaN   \n",
       "1                 NaN                  54.0                                          NaN   \n",
       "2                 NaN                  45.0                                          NaN   \n",
       "3                 NaN                  37.0                                          NaN   \n",
       "4                 NaN                  41.0                                          NaN   \n",
       "\n",
       "   smart_195_normalized_max_7  smart_195_normalized_min_7  smart_195_normalized_std_7  \\\n",
       "0                        52.0                        52.0                         NaN   \n",
       "1                        54.0                        54.0                         NaN   \n",
       "2                        45.0                        45.0                         NaN   \n",
       "3                        37.0                        37.0                         NaN   \n",
       "4                        41.0                        41.0                         NaN   \n",
       "\n",
       "  smart_197raw smart_198raw  smart_199raw  smart_199raw_diff_for_last_period_7  \\\n",
       "0          0.0          0.0           0.0                                  NaN   \n",
       "1          0.0          0.0           0.0                                  NaN   \n",
       "2          0.0          0.0           0.0                                  NaN   \n",
       "3          0.0          0.0           0.0                                  NaN   \n",
       "4          0.0          0.0           0.0                                  NaN   \n",
       "\n",
       "   smart_199raw_max_7  smart_199raw_min_7  smart_199raw_std_7  smart_1_normalized  \\\n",
       "0                 0.0                 0.0                 NaN                81.0   \n",
       "1                 0.0                 0.0                 NaN                80.0   \n",
       "2                 0.0                 0.0                 NaN                81.0   \n",
       "3                 0.0                 0.0                 NaN                68.0   \n",
       "4                 0.0                 0.0                 NaN                83.0   \n",
       "\n",
       "   smart_1_normalized_diff_for_last_period_7  smart_1_normalized_max_7  smart_1_normalized_min_7  \\\n",
       "0                                        NaN                      81.0                      81.0   \n",
       "1                                        NaN                      80.0                      80.0   \n",
       "2                                        NaN                      81.0                      81.0   \n",
       "3                                        NaN                      68.0                      68.0   \n",
       "4                                        NaN                      83.0                      83.0   \n",
       "\n",
       "   smart_1_normalized_std_7  smart_3_normalized  smart_3_normalized_diff_for_last_period_7  \\\n",
       "0                       NaN                96.0                                        NaN   \n",
       "1                       NaN                95.0                                        NaN   \n",
       "2                       NaN                96.0                                        NaN   \n",
       "3                       NaN                87.0                                        NaN   \n",
       "4                       NaN                97.0                                        NaN   \n",
       "\n",
       "   smart_3_normalized_max_7  smart_3_normalized_min_7  smart_3_normalized_std_7  smart_4raw  \\\n",
       "0                      96.0                      96.0                       NaN        20.0   \n",
       "1                      95.0                      95.0                       NaN        12.0   \n",
       "2                      96.0                      96.0                       NaN        21.0   \n",
       "3                      87.0                      87.0                       NaN         7.0   \n",
       "4                      97.0                      97.0                       NaN         6.0   \n",
       "\n",
       "   smart_4raw_diff_for_last_period_7  smart_4raw_max_7  smart_4raw_min_7  smart_4raw_std_7  \\\n",
       "0                                NaN              20.0              20.0               NaN   \n",
       "1                                NaN              12.0              12.0               NaN   \n",
       "2                                NaN              21.0              21.0               NaN   \n",
       "3                                NaN               7.0               7.0               NaN   \n",
       "4                                NaN               6.0               6.0               NaN   \n",
       "\n",
       "   smart_5raw  smart_5raw_diff_for_last_period_7  smart_5raw_max_7  smart_5raw_min_7  \\\n",
       "0         0.0                                NaN               0.0               0.0   \n",
       "1        27.0                                NaN              27.0              27.0   \n",
       "2         0.0                                NaN               0.0               0.0   \n",
       "3        48.0                                NaN              48.0              48.0   \n",
       "4         1.0                                NaN               1.0               1.0   \n",
       "\n",
       "   smart_5raw_slope_for_last_duration_7  smart_5raw_std_7  smart_7_normalized  \\\n",
       "0                                   NaN               NaN                85.0   \n",
       "1                                   NaN               NaN                93.0   \n",
       "2                                   NaN               NaN                92.0   \n",
       "3                                   NaN               NaN                86.0   \n",
       "4                                   NaN               NaN                84.0   \n",
       "\n",
       "   smart_7_normalized_diff_for_last_period_7  smart_7_normalized_max_7  smart_7_normalized_min_7  \\\n",
       "0                                        NaN                      85.0                      85.0   \n",
       "1                                        NaN                      93.0                      93.0   \n",
       "2                                        NaN                      92.0                      92.0   \n",
       "3                                        NaN                      86.0                      86.0   \n",
       "4                                        NaN                      84.0                      84.0   \n",
       "\n",
       "   smart_7_normalized_std_7  smart_9_normalized  tag  \n",
       "0                       NaN                 8.0    1  \n",
       "1                       NaN                20.0    1  \n",
       "2                       NaN                29.0    1  \n",
       "3                       NaN                11.0    1  \n",
       "4                       NaN                18.0    1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fe_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart_187_normalized',\n",
       " 'smart_189_normalized',\n",
       " 'smart_189_normalized_diff_for_last_period_7',\n",
       " 'smart_189_normalized_max_7',\n",
       " 'smart_189_normalized_min_7',\n",
       " 'smart_189_normalized_std_7',\n",
       " 'smart_191_normalized',\n",
       " 'smart_191_normalized_diff_for_last_period_7',\n",
       " 'smart_191_normalized_max_7',\n",
       " 'smart_191_normalized_min_7',\n",
       " 'smart_191_normalized_std_7',\n",
       " 'smart_193_normalized',\n",
       " 'smart_193_normalized_diff_for_last_period_7',\n",
       " 'smart_193_normalized_max_7',\n",
       " 'smart_193_normalized_min_7',\n",
       " 'smart_193_normalized_std_7',\n",
       " 'smart_195_normalized',\n",
       " 'smart_195_normalized_diff_for_last_period_7',\n",
       " 'smart_195_normalized_max_7',\n",
       " 'smart_195_normalized_min_7',\n",
       " 'smart_195_normalized_std_7',\n",
       " 'smart_1_normalized',\n",
       " 'smart_1_normalized_diff_for_last_period_7',\n",
       " 'smart_1_normalized_max_7',\n",
       " 'smart_1_normalized_min_7',\n",
       " 'smart_1_normalized_std_7',\n",
       " 'smart_3_normalized',\n",
       " 'smart_3_normalized_diff_for_last_period_7',\n",
       " 'smart_3_normalized_max_7',\n",
       " 'smart_3_normalized_min_7',\n",
       " 'smart_3_normalized_std_7',\n",
       " 'smart_7_normalized',\n",
       " 'smart_7_normalized_diff_for_last_period_7',\n",
       " 'smart_7_normalized_max_7',\n",
       " 'smart_7_normalized_min_7',\n",
       " 'smart_7_normalized_std_7',\n",
       " 'smart_9_normalized']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in fe_df.columns if 'normalized' in col.split('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['degradation_err_weight',\n",
       " 'degradation_err_weight_diff_for_last_period_7',\n",
       " 'degradation_err_weight_max_7',\n",
       " 'degradation_err_weight_min_7',\n",
       " 'degradation_err_weight_std_7',\n",
       " 'dt',\n",
       " 'err_weight',\n",
       " 'err_weight_diff_for_last_period_7',\n",
       " 'err_weight_max_7',\n",
       " 'err_weight_min_7',\n",
       " 'err_weight_std_7',\n",
       " 'flag',\n",
       " 'model',\n",
       " 'model_type',\n",
       " 'seek_err_weight',\n",
       " 'seek_err_weight_diff_for_last_period_7',\n",
       " 'seek_err_weight_max_7',\n",
       " 'seek_err_weight_min_7',\n",
       " 'seek_err_weight_std_7',\n",
       " 'serial_number',\n",
       " 'smart_12raw',\n",
       " 'smart_12raw_diff_for_last_period_7',\n",
       " 'smart_12raw_max_7',\n",
       " 'smart_12raw_min_7',\n",
       " 'smart_12raw_std_7',\n",
       " 'smart_184raw',\n",
       " 'smart_188raw',\n",
       " 'smart_192raw',\n",
       " 'smart_192raw_diff_for_last_period_7',\n",
       " 'smart_192raw_max_7',\n",
       " 'smart_192raw_min_7',\n",
       " 'smart_192raw_std_7',\n",
       " 'smart_194raw',\n",
       " 'smart_194raw_diff_for_last_period_7',\n",
       " 'smart_194raw_max_7',\n",
       " 'smart_194raw_min_7',\n",
       " 'smart_194raw_std_7',\n",
       " 'smart_197raw',\n",
       " 'smart_198raw',\n",
       " 'smart_199raw',\n",
       " 'smart_199raw_diff_for_last_period_7',\n",
       " 'smart_199raw_max_7',\n",
       " 'smart_199raw_min_7',\n",
       " 'smart_199raw_std_7',\n",
       " 'smart_4raw',\n",
       " 'smart_4raw_diff_for_last_period_7',\n",
       " 'smart_4raw_max_7',\n",
       " 'smart_4raw_min_7',\n",
       " 'smart_4raw_std_7',\n",
       " 'smart_5raw',\n",
       " 'smart_5raw_diff_for_last_period_7',\n",
       " 'smart_5raw_max_7',\n",
       " 'smart_5raw_min_7',\n",
       " 'smart_5raw_slope_for_last_duration_7',\n",
       " 'smart_5raw_std_7',\n",
       " 'tag']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in fe_df.columns if 'normalized' not in col.split('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
